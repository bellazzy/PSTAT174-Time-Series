---
title: "pstat174 final project code part"
author: "zhongyun zhang"
date: "5/26/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This consumer confidence indicator provides an indication of future developments of households??? consumption and saving, based upon answers regarding their expected financial situation, their sentiment about the general economic situation, unemployment and capability of savings. An indicator above 100 signals a boost in the consumers??? confidence towards the future economic situation, as a consequence of which they are less prone to save, and more inclined to spend money on major purchases in the next 12 months. Values below 100 indicate a pessimistic attitude towards future developments in the economy, possibly resulting in a tendency to save more and consume less.

```{r}
#install.packages("MASS")
library("MASS")
```

```{r}
#data from Jan2010 to feb2021 of United States
setwd("~/Desktop")
confidence <- read.csv("~/Desktop/consumer_confidence.csv")
#head(confidence)
```

```{r}
value <- confidence[1:134,7]
data_ts <- ts(value, start = c(2010,1), frequency = 12)
ts.plot(data_ts,xlab="time", ylab="confidence index", main="Time Series for CCI")
```

```{r}
#split data into training set and test set
train <- confidence[1:122,7]
test <- confidence[123:134,7]
```

```{r}
# According to the histogram we decide to transform the data
par(mfrow = c(1,2))
hist(train, main = "Histogram of CCI", xlab = "CCI")

train_ts <- ts(train)
ts.plot(train_ts, main="Training Time Series Plot")
#box-cox transformation
t <- as.numeric(1:length(train_ts))
fit <- lm(train_ts ~ t)
#bcTransform <- boxcox(train_ts ~ t, plotit = TRUE)
lambda <- bcTransform$x[which(bcTransform$y == max(bcTransform$y))]
lambda
train_bc <- (1/lambda)*(train_ts^lambda - 1)
```
```{r}
#log transform
train_log <- log(train_ts)
```

```{r}
#square root transform
train_sqrt <- sqrt(train_ts)
```



```{r}
#compare transforms
par(mfrow = c(2,2))
ts.plot(train_ts, main = "Original data")
ts.plot(train_bc, main = "Box-Cox transformed data")
ts.plot(train_log, main = "Log transformed data")
ts.plot(train_sqrt, main = "Square root transformed data")
```

```{r}
#compare histogram
par(mfrow = c(2,2))
hist(train_ts, col="pink", main="Original")
hist(train_bc, col="pink", main="Transformed with Box-Cox")
hist(train_log, col="pink", main="Transformed with Log")
hist(train_sqrt, col="pink", main="Transformed with square root ")
```

```{r}
ts.plot(train_ts, main = "Original data")
abline(abline(fit), col = "red", lty = 2)
#original variance & acf/pacf
print(paste("Variance of original data is",var(train_ts)))
acf(train_ts, lag.max = 40, main="")
title("ACF of CCI", line = -1, outer = TRUE)
pacf(train_ts, lag.max = 40, main="")
title("PACF of CCI", line = -1, outer = TRUE)
```


```{r}
print(paste("Original vairance", var(train)))
dtrain <- diff(train_ts, lag = 12)
ddtrain <- diff(dtrain, lag = 1)

par(mfrow = c(1,2))
ts.plot(dtrain)
abline(lm(dtrain~as.numeric(1:length(dtrain))), col = "red", lty = 2)
print(paste("Variance differenced at lag 12 is", var(dtrain)))

ts.plot(ddtrain)
abline(lm(ddtrain~as.numeric(1:length(ddtrain))), col = "red", lty = 2)
print(paste("Variance differenced at lag 12 and 1 is", var(ddtrain)))

par(mfrow = c(1,2))
hist(dtrain)
hist(ddtrain)
```

```{r}
acf(ddtrain, lag.max = 40)
title("ACF of CCI", line = -1, outer = TRUE)
pacf(dtrain, lag.max = 40)
title("PACF of CCI", line = -1, outer = TRUE)
```

Now, I plot ACF and PACF plot after differencing at lag 12 and lag 1.
For the seasonal part (P, D, Q):

For ACF, I look at h = 12s, 24s, 36s, etc. The ACF shows a strong peak at h = 12s. A good choice for the MA part could be Q = 1.

For PACF, I also look at h = 12s, 24s, 36s, etc. The PACF shows A strong peaks at h = 12s. While for h = 24, it is really close to the 95 \% confidence interval. A good choice for the AR part could be P = 1 or P = 2 or maybe P = 0.

When modeling the non-seasonal part (p, d, q): In this case focus on the within season lags, h = 1,. . . ,11.

We applied one differencing to remove the trend: d = 1

The ACF seems to be tailing off, or perhaps cuts of at lag. A good choice for the MA part could be q = 5.
The PACF cuts off at 3.
A good choice for the AR part could be up to 3.

(0,1,0)x(0,1,0) 12
(1,1,0)x(0,1,1) 12
(2,1,1)x(1,1,0) 12
(0,1,0)x(1,1,1) 12


```{r}
auto.arima(train)
```

```{r}
arima(train, order=c(2,1,0), seasonal = list(order = c(1,1,0), period = 12), method="ML")
```
 
```{r}
arima(train, order=c(2,1,0), seasonal = list(order = c(1,1,0), period = 12), method="ML")
```

```{r}
arima(train, order=c(2,1,0), seasonal = list(order = c(2,1,0), period = 12), method="ML")
```


```{r}
#install.packages("AICcmodavg")
library(AICcmodavg)
#install.packages("rgl")
library(rgl)
#install.packages("qpcR")
library(qpcR)
#install.packages("UnitCircle")
library(UnitCircle)
```



```{r}
arima(train, order=c(2,1,0), seasonal = list(order = c(2,1,1), period = 12), method="ML")
```
```{r}
#install.packages("astsa")
library(astsa)
```

```{r}
fit.i <-arima(train, order=c(2,1,0), seasonal = list(order = c(2,1,1), period = 12),method="ML")
```

```{r}
# Statistics of the residuals:
res <- residuals(fit.i) 
m <- mean(res)
ts.plot(res, main = "Fitted Residuals")
abline(h = mean(res), col = "red")
```

```{r}
par(mfrow = c(1,2))
# Check the normality assumption:
hist(res,main = "Histogram") 
qqnorm(res)
qqline(res, col="blue")
#title("Fitted Residuals Diagnostics", outer = TRUE)
```

```{r}
# Test for the normality of residuals:
shapiro.test(res)
```

```{r}
#95% ci
par(mfrow=c(1, 2))
acf(res,main = "Autocorrelation")
pacf(res,main = "Partial Autocorrelation")
```

```{r}
## Test for independence of residuals:
Box.test(res, lag=12, type=c("Box-Pierce"), fitdf=5)
Box.test(res, lag=12, type=c("Ljung-Box"), fitdf=5)
Box.test(res^2, lag=12, type=c("Ljung-Box"), fitdf=0)
```

```{r}
ar(res, aic = TRUE, order.max = NULL, method = c("yule-walker"))
```

```{r}
#check for invertibility and causality
uc.check(pol_=c(1,-1.1710,0.6825), plot_output = TRUE)
```

```{r}
#check for invertibility and causality
uc.check(pol_=c(1,-1.1718,0.6717), plot_output = TRUE)
```
2,1,1,2,1,0 ok
2,1,0,2,1,1 no
2,1,1,0,1,3 ok
```{r}

# Predict 12 future observations and plot
mypred = predict(fit.i, n.ahead=12)
U.tr= pred.tr$pred + 2*pred.tr$se
L.tr= pred.tr$pred - 2*pred.tr$se
ts.plot(confidence, xlim=c(1,length(train)+12), ylim = c(80,max(U.tr)))
lines(U.tr, col="blue", lty="dashed")
lines(L, col="blue", lty="dashed")
points((length(train)+1):(length(train)+12), col="red")

```
```{r}
pred.tr <- predict(fit.i, n.ahead= 12)
upper= pred.tr$pred + 2*pred.tr$se
lower= pred.tr$pred - 2*pred.tr$se
ts.plot(confidence, xlim=c(122,length(train)+12), ylim= c(90,max(upper)+5))
lines(upper, col="blue", lty="dashed")
lines(lower, col="blue", lty="dashed")
points((length(train)+1):(length(train)+12), pred.tr$pred, col="red")
points((length(train)+1):(length(train)+12),unlist(test),col="blue")


```
